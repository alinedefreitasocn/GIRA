{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ad4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json, urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809472a1",
   "metadata": {},
   "source": [
    "Reading the first file: `estacoes-gira-2--semestre-2022.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7390c07",
   "metadata": {},
   "source": [
    "The join() function from the os.path module creates a path in the format required by the operating system upon which the code is being run (i.e. whatever operating system your computer is running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ff801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the curring working directory\n",
    "#path = os.getcwd() \n",
    "#data_path = os.path.join(path, 'GIRA/')\n",
    "data_path = '/mnt/d/Dados/FinalProject_GIRA/GIRA'\n",
    "entries = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f247cfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estacoes-gira-2semestre-2022.csv',\n",
       " 'JSON_ciclovias.txt',\n",
       " 'README.md.txt',\n",
       " 'weather_docas_2020.csv',\n",
       " 'GIRA_presentation.pdf',\n",
       " 'GIRA.ipynb',\n",
       " 'estacoes-gira-1semestre-2022.csv',\n",
       " 'gira1t2020.xlsx',\n",
       " 'gira2t2020.xlsx',\n",
       " 'gira3t2020.xlsx',\n",
       " 'gira4t2020.xlsx',\n",
       " 'Gira_2023_05_26.csv',\n",
       " 'gira_lisboaaberta_one_day2023_05_26.csv',\n",
       " 'gira---bicicletas-de-lisboa-2021.7z']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318487f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, entries[0]), \n",
    "                 parse_dates=['entity_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62e641b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desigcomercial</th>\n",
       "      <th>numbicicletas</th>\n",
       "      <th>numdocas</th>\n",
       "      <th>position</th>\n",
       "      <th>entity_ts</th>\n",
       "      <th>estado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135 - Avenida Cidade de Lourenço Marques / Val...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>{\"coordinates\":[-9.118689,38.764067],\"type\":\"P...</td>\n",
       "      <td>2022-07-27 15:53:45.206000+00:00</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456 - Entrecampos / Av. das Forças Armadas</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>{\"coordinates\":[-9.14872,38.74877],\"type\":\"Poi...</td>\n",
       "      <td>2022-07-27 15:53:46.819000+00:00</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132 - Avenida de Berlim / Rua Cidade de Cabinda</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{\"coordinates\":[-9.11255,38.76829],\"type\":\"Poi...</td>\n",
       "      <td>2022-07-27 15:53:44.936000+00:00</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      desigcomercial  numbicicletas  numdocas  \\\n",
       "0  135 - Avenida Cidade de Lourenço Marques / Val...              7        20   \n",
       "1         456 - Entrecampos / Av. das Forças Armadas             18        41   \n",
       "2    132 - Avenida de Berlim / Rua Cidade de Cabinda              2        25   \n",
       "\n",
       "                                            position  \\\n",
       "0  {\"coordinates\":[-9.118689,38.764067],\"type\":\"P...   \n",
       "1  {\"coordinates\":[-9.14872,38.74877],\"type\":\"Poi...   \n",
       "2  {\"coordinates\":[-9.11255,38.76829],\"type\":\"Poi...   \n",
       "\n",
       "                         entity_ts  estado  \n",
       "0 2022-07-27 15:53:45.206000+00:00  active  \n",
       "1 2022-07-27 15:53:46.819000+00:00  active  \n",
       "2 2022-07-27 15:53:44.936000+00:00  active  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fddbcd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desigcomercial    0\n",
       "numbicicletas     0\n",
       "numdocas          0\n",
       "position          0\n",
       "entity_ts         0\n",
       "estado            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685206d",
   "metadata": {},
   "source": [
    "## Organizing the data\n",
    "\n",
    "- The station ID is a string with the station name. I want it as a separate column.\n",
    "- The coordinates are into a single column and as a string. I want it as a float and in two different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8531fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['station_name'] = df['desigcomercial'].str.split('-').str[1]\n",
    "df.drop(columns=['desigcomercial', 'position'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stationID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635ec6e",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "I want the data sorted by station ID and timestamp. With this information we could check the diff in the timestamp column and realize that it's not homogeneous. My idea is to transform it into periods of the day: 'morning', 'lunch time', 'afternoon', 'night'.\n",
    "\n",
    "After sorting, I can calculate the number of bicicles taken by taking the difference in number of bicicles column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the dataframe by stationID and time\n",
    "df.sort_values(by=['entity_ts'], inplace=True) # 'stationID', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efeaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc509aad",
   "metadata": {},
   "source": [
    "## Drop duplicates\n",
    "\n",
    "By checking the time, I realize there are some duplicates, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec332d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeee36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073b8951",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stationID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stationID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# checking the first station\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m st101 \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstationID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m101\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stationID'"
     ]
    }
   ],
   "source": [
    "# checking the first station\n",
    "st101 = df[df['stationID'] == 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b80b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101['diff_time'] = st101['entity_ts'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf91d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(st101['entity_ts'], np.ones(len(st101)), marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64bf6bb",
   "metadata": {},
   "source": [
    "2382896 observations with distinct time distribution, from 27 of June, 2022 to 16 of February, 2023 (about 6 months long). Info about station name, number of bicicles, number os docs (constant), position information (as string) and a date string. Will be cosidered as time series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33359ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101['bike_taken'] = df['numbicicletas'].diff().fillna(0)\n",
    "\n",
    "# I dont care about the positives values now, so I will set it to zero\n",
    "st101['bike_taken'][st101['bike_taken'] > 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(st101['entity_ts'], st101['bike_taken']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef60d7",
   "metadata": {},
   "source": [
    "## Split the day into periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_time(x:pd.Series) -> str:\n",
    "    if x.hour >= 6 and x.hour <= 11:\n",
    "        return 'morning'\n",
    "    elif x.hour >= 12 and x.hour <= 15 :\n",
    "        return 'lunch'\n",
    "    elif x.hour >= 16 and x.hour <= 20:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'night'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23706d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101['period'] = st101['entity_ts'].apply(period_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bae4e",
   "metadata": {},
   "source": [
    "Now the ts can be just the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101['date'] = st101['entity_ts'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce973e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727dee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "st101.groupby(by=['date','period']).agg({\n",
    "    'bike_taken': 'sum',\n",
    "    'stationID': 'last',\n",
    "    'station_name': 'last',\n",
    "    'lat': 'last',\n",
    "    'lon': 'last'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7838a2",
   "metadata": {},
   "source": [
    "# Map by time\n",
    "\n",
    "I think I need to resample the data to hourly and fill up the gaps with the mean between to steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the date to index\n",
    "df.set_index('entity_ts', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a26590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0294998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to get data every 1 hour\n",
    "df_hour = df.resample('H').agg({'numbicicletas': 'mean',\n",
    "                      'lat': 'last',\n",
    "                      'lon': 'last',\n",
    "                      'station_name': 'last',\n",
    "                      'stationID': 'last',\n",
    "                      'estado': 'last'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buble map with animation from plotly\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_geo(data_frame=df_hour, \n",
    "                     lat='lat', \n",
    "                     lon='lon',\n",
    "                     color=\"numbicicletas\",\n",
    "                     hover_name=\"stationID\", #size=\"numbicicletas\",\n",
    "                     animation_frame=df_hour.index,\n",
    "                     projection=\"natural earth\",\n",
    "                     #scope='europe'\n",
    "                     )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723eee91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
